{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "데이터 추출.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCQ-uoJiJ3TL"
      },
      "outputs": [],
      "source": [
        "# <colab에서 실행>\n",
        "\n",
        "# 기본 라이브러리 임포트\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob # glob 모듈의 glob 함수는 사용자가 제시한 조건에 맞는 파일명을 리스트 형식으로 반환한다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 구글 드라이브와 연동한다.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "5uzSjbNHJ5sw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# audio 폴더를 만든다.\n",
        "import os\n",
        "os.mkdir('/content/drive/MyDrive/ColabNotebooks/audio')"
      ],
      "metadata": {
        "id": "zPvfWO68J-Qz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ColabNotebooks에서 audio 데이터를 zip으로 업로드 후 audio 폴더에 압축을 푼다.\n",
        "!unzip -qq /content/drive/MyDrive/ColabNotebooks/audio.zip  -d /content/drive/MyDrive/ColabNotebooks/audio"
      ],
      "metadata": {
        "id": "-s9v3JylJ_wV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모든 개와 고양이 소리가 있는 위치+파일명을 X_path에 넣는 작업을 한다.\n",
        "import tensorflow as tf\n",
        "\n",
        "# seed값 설정\n",
        "tf.random.set_seed(777)\n",
        "\n",
        "Test_root_b = glob.glob('/content/drive/MyDrive/ColabNotebooks/audio/birds')[0] \n",
        "Test_root_c = glob.glob('/content/drive/MyDrive/ColabNotebooks/audio/cats')[0] \n",
        "Test_root_d = glob.glob('/content/drive/MyDrive/ColabNotebooks/audio/dogs')[0] \n",
        "\n",
        "print(Test_root_b) #bird 경로 담기\n",
        "print(Test_root_c) #cats 경로 담기\n",
        "print(Test_root_d) #dogs 경로 담기"
      ],
      "metadata": {
        "id": "7-M76tp6KDia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모든 개, 고양이, 새 소리가 있는 위치와 파일명을 X_path 에 넣는 작업을 한다.\n",
        "X_path = glob.glob(Test_root_b+\"/test/*\")\n",
        "X_path = X_path + glob.glob(Test_root_c + \"/test/*\")\n",
        "X_path = X_path + glob.glob(Test_root_d + \"/test/*\")\n",
        "X_path = X_path + glob.glob(Test_root_b + \"/train/*\")\n",
        "X_path = X_path + glob.glob(Test_root_c + \"/train/*\")\n",
        "X_path= X_path + glob.glob(Test_root_d + \"/train/*\")"
      ],
      "metadata": {
        "id": "ds_tI6AcKQkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 정답 데이터 만드는 코드(새는 0, 고양이는 1, 강아지는 2로 지정)\n",
        "\n",
        "import ntpath # 특정 경로에서 파일들을 가져오는 라이브러리\n",
        "y = np.empty((0, 1, )) \n",
        "for f in X_path:\n",
        "    if 'birds' in f: #  음성 데이터가 있는 디렉토리의 데이터가 새 음성 데이터라면 \n",
        "        resp = np.array([0])  #   [0]  , 1차원\n",
        "        resp = resp.reshape(1, 1, ) # [[0]]  , 2차원 --> 추후 원핫인코딩에 넣기 위해서\n",
        "        y = np.vstack((y, resp))  # array([[0.]]) , 배열을 세로로 결합 , 데이터가 세로로 쌓인다. \n",
        "    elif 'cats' in f: # 음성 데이터가 있는 디렉토리의 데이터가 고양이 음성 데이터라면\n",
        "        resp = np.array([1])  # [1] \n",
        "        resp = resp.reshape(1, 1, ) #[[1]]\n",
        "        y = np.vstack((y, resp)) # \n",
        "    elif 'dogs' in f: # 음성 데이터가 있는 디렉토리의 데이터가 개 음성 데이터라면\n",
        "        resp = np.array([2])  # [2] \n",
        "        resp = resp.reshape(1, 1, ) #[[2]]\n",
        "        y = np.vstack((y, resp)) # \n",
        "\n",
        "print(len(y)) #1084"
      ],
      "metadata": {
        "id": "TJU7Q5MHKTvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 데이터와 테스트 데이터를 분리한다.\n",
        "# 훈련 90%, 테스트 10% 로 구성한다.\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_path, y, test_size=0.1, random_state=42)\n",
        "\n",
        "print(len(X_train)) # 975\n",
        "print(len(X_test))  # 109\n",
        "print(len(y_train)) # 975\n",
        "print(len(y_test)) # 109"
      ],
      "metadata": {
        "id": "VxejK4ouKauU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 개, 고양이, 새 음성에서 진폭을 추출해서 리스트에 담는 함수를 생성한다.\n",
        "    \n",
        "import librosa # 음원 데이터에서 신경망 학습을 시킬 수 있는 데이터를 뽑아내는 모듈\n",
        "\n",
        "def librosa_read_wav_files(wav_files):\n",
        "    if not isinstance(wav_files, list): \n",
        "        wav_files = [wav_files]  # 리스트화 \n",
        "    return [librosa.load(f)[0] for f in wav_files] # 진폭과 샘플레이트중 진폭만 담는다. \n",
        "\n",
        "wav_rate = librosa.load(X_train[0])[1] \n",
        "wav_rate  # 훈련 데이터의 첫번째 동물의 sample rate 값을 wave_rate 에 담는다.\n",
        "\n",
        "X_train = librosa_read_wav_files(X_train)  # 훈련 데이터 975개의 진폭 데이터를 X_train 담는다.\n",
        "X_test  = librosa_read_wav_files(X_test)   # 테스트 데이터 109개의 진폭 데이터를 X_test 에 담는다.\n",
        "\n",
        "print(len(X_train))  # 975개의 진폭 데이터 리스트\n",
        "print(len(X_test))   # 109개의 진폭 데이터 리스트 "
      ],
      "metadata": {
        "id": "qJfCXeHwKhy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 음성 특징 추출 함수\n",
        "def extract_features(audio_samples, sample_rate): \n",
        "    extracted_features = np.empty((0, 61, )) \n",
        "    if not isinstance(audio_samples, list):\n",
        "        audio_samples = [audio_samples] # 리스트화 한다.\n",
        "    for sample in audio_samples:  # 진폭 데이터 리스트를 하나씩 가져온다.\n",
        "        zero_cross_feat = librosa.feature.zero_crossing_rate(sample).mean() \n",
        "        mfccs = librosa.feature.mfcc(y=sample, sr=sample_rate, n_mfcc=60) \n",
        "        mfccsscaled = np.mean(mfccs.T,axis=0)  \n",
        "        mfccsscaled = np.append(mfccsscaled, zero_cross_feat)  \n",
        "        mfccsscaled = mfccsscaled.reshape(1, 61, )  \n",
        "        extracted_features = np.vstack((extracted_features, mfccsscaled)) \n",
        "    return extracted_features"
      ],
      "metadata": {
        "id": "Bx8LdxJuKmrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train과 test 데이터를 음성 특징 추출하여 담는다.\n",
        "X_train_features = extract_features(X_train, wav_rate) \n",
        "X_test_features  = extract_features(X_test, wav_rate)\n",
        "print(len(X_train_features))\n",
        "print(len(X_test_features))"
      ],
      "metadata": {
        "id": "jPub3B7jKsId"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}